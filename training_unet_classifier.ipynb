{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lib imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#local imports\n",
    "from utils import *\n",
    "from plotting import *\n",
    "from model_creator import *\n",
    "from mediapipe_utils.mediapipe_transforamtions import *\n",
    "\n",
    "print('TensorFlow version: ', tf.__version__)\n",
    "print('Keras version: ', keras.__version__)\n",
    "print('Python version: ', os.sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = './'\n",
    "original_data_dir = os.path.join(local_dir, 'unet_utils/postprocessed_segmented_data')\n",
    "# src_data contains the original data from the Kaggle dataset together with the augmented data from 'resized_images'\n",
    "dataset_dir = os.path.join(local_dir, 'dataset_unet_classifiers')\n",
    "models_dir = os.path.join(local_dir, 'models_unet_classifiers')\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'val')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "src_data = os.path.join(local_dir, 'src_data')\n",
    "assert os.path.exists(src_data), f'{src_data} not found'\n",
    "\n",
    "classes = ['rock', 'paper', 'scissors']\n",
    "\n",
    "\n",
    "if not os.path.exists(original_data_dir):\n",
    "    raise FileNotFoundError('Original data directory not found')\n",
    "\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "    split_dataset(classes, original_data_dir, dataset_dir)\n",
    "\n",
    "for path in [train_dir, val_dir, test_dir]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f'{path} not found')\n",
    "    \n",
    "    print(path)\n",
    "    for class_name in classes:\n",
    "        print(f'    - {class_name}: {len(os.listdir(os.path.join(path, class_name)))} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_for_duplicates_in_dataset\n",
    "check_for_duplicates_in_dataset('./dataset_unet_classifiers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image target size\n",
    "img_rows, img_cols = 128, 128\n",
    "batch_size = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,  \n",
    "    width_shift_range=0.1,  \n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1,  \n",
    "    zoom_range=[0.8, 1.2], \n",
    "    horizontal_flip=True,  \n",
    "    fill_mode='constant'  \n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    zoom_range=[0.9, 1.1],\n",
    "    fill_mode='constant'\n",
    "    )\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale',\n",
    "    )\n",
    "\n",
    "plot_grid_from_generator(train_generator, 5, 5, cmap='gray')\n",
    "plot_grid_from_generator(val_generator, 2, 5, cmap='gray')\n",
    "plot_grid_from_generator(test_generator, 2, 5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "MODEL_NAME = 'cnn_unet_classifier'\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(models_dir, f'{MODEL_NAME}_ckp.keras'),\n",
    "    save_weights_only=False,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "csvlogger_callback = tf.keras.callbacks.CSVLogger(\n",
    "    filename=os.path.join(models_dir, f'{MODEL_NAME}_ckp_history.csv'),     \n",
    "    separator=',',                      \n",
    "    append=True                           \n",
    ")\n",
    "\n",
    "# Channels: 1 for grayscale (3 for RGB), arg 'input_shape' in the model\n",
    "hist_dict = compile_and_train_model(\n",
    "    create_model_func=build_cnn_medium,\n",
    "    create_model_args={'input_shape' : (128, 128, 1), 'num_classes' :3},\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'], \n",
    "    train_generator=train_generator,\n",
    "    val_generator=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    models_dir=models_dir,\n",
    "    model_name=MODEL_NAME,\n",
    "    callbacks=[checkpoint_callback, csvlogger_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(os.path.join(models_dir, f'{MODEL_NAME}_ckp.keras'))\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_csv(os.path.join(models_dir, f'{MODEL_NAME}_history.csv'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
